# Create a 'python' directory in the workspace to store the MapReduce project files.
mkdir ~/workspace/python

# Navigate to the newly created 'python' directory.
cd ~/workspace/python

# Open nano text editor to create the 'mapper.py' script.
nano mapper.py

# This mapper script reads input lines, splits them into words, and prints each word with a count of 1.
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
        print('%s\t%s' % (word, 1))


# Open nano text editor to create the 'reducer.py' script.
nano reducer.py

# This reducer script sums the counts for each word, producing the total count for each word.
#!/usr/bin/env python3
import sys

current_word = None
current_count = 0
word = None

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t', 1)

    try:
        count = int(count)
    except ValueError:
        continue

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print('%s\t%s' % (current_word, current_count))
        current_count = count
        current_word = word

if current_word == word:
    print('%s\t%s' % (current_word, current_count))

# Run the MapReduce job, specifying the input file, output directory, mapper, and reducer scripts.
hadoop jar /home/hadoop/hadoop-3.2.2/share/hadoop/tools/lib/hadoop-streaming-3.2.2.jar -input boardgamerev.csv -output pc4 -file mapper.py -file reducer.py -mapper mapper.py -reducer reducer.py

# List the files in the output directory to verify the MapReduce job completion.
hadoop fs -ls /user/hadoop/pc4

# Display the content of the output file to validate the results of the word count operation.
hadoop fs -cat /user/hadoop/pc4/part-00000| sort -k2,2nr | more
